apiVersion: "kafka.strimzi.io/v1beta2"
kind: "KafkaConnector"
metadata:
  # connector name
  name: "sink-s3-products"
  namespace: kafka
  labels:
    # kafka connect [cluster] name
    strimzi.io/cluster: kafka-class
spec:
  class: io.confluent.connect.s3.S3SinkConnector
  tasksMax: 1
  config:
    key.converter: "org.apache.kafka.connect.storage.StringConverter"
    value.converter: "org.apache.kafka.connect.json.JsonConverter"
    key.converter.schemas.enable: "false"
    value.converter.schemas.enable: "false"
    topics: "mssql-products"
    s3.bucket.name: "dl-landing-zone-539445819060"
    topics.dir: sales_domain/kafka_events
    s3.region: "us-east-1"
    s3.part.size: 5242880
    flush.size: 500
    rotate.schedule.interval.ms: 5000
    aws.access.key.id: "${file:/opt/kafka/external-configuration/connector-config-aws-s3/aws-s3-credentials.properties:aws_access_key_id}"
    aws.secret.access.key: "${file:/opt/kafka/external-configuration/connector-config-aws-s3/aws-s3-credentials.properties:aws_secret_access_key}"
    storage.class: "io.confluent.connect.s3.storage.S3Storage"
    format.class: "io.confluent.connect.s3.format.json.JsonFormat"
    schema.generator.class: "io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator"
    partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
    path.format: "YYYY-MM-dd/HH"
    locale: "pt_BR"
    timezone: "America/Sao_Paulo"
    partition.duration.ms: 18000
    timestamp.extractor: "Record"